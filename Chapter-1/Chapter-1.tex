\chapter{INTRODUCTION}
\label{chap-one}

\begin{flushright}

  ``It is not competition that drives processes,
  \\but rather the inventive collaborations of density.''
  \\- Steven Johnson, \textit{Where Good Ideas Come From}
  \line(1,0){250}
\end{flushright}

#edit3

On June 3, 2016, Jeff Sandquist, the General Manager in the Cloud \& Enterprise Division (as of March 2020) at Microsoft published an article on the Team blog \cite{sandquist}, the space that Microsoft’s documentation team uses to publish their news and updates about the documentation website. The announcement notified users about the new features they released to the documentation site (for some products which were cloud-based). The features were meant to improve users' experience as they continued to use the company’s documentation website. The post contended that this step was a response to user feedback about their documentation that they had been collecting over a long period of time. The post suggested that the team evaluated the feedback and tried to find ways to create a better experience. However, it could not be done with the infrastructure they were using to publish documentation. Several reforms were made in order to change the ways in which knowledge was “created and consumed”. Reforms on an organizational level are never sufficient. Stakeholders need to be trained to adapt to new knowledge consumption models. For example, while discussing his experience at Bell Labs, Dicks also described the considerable effort in training, retooling, and redefinition required for both writers and users when the publishing approach is changed \cite{dicks1994integrating}. Microsoft’s blog post served the rhetorical purpose of informing users of the new approaches carried out to bring about a positive change with respect to their experience of the documentation website.

Out of all the features mentioned in the post, ‘Community contributions’ gained a lot of attention from users as well as technical communication teams at other organizations. The responses on this post (found at the bottom of the post - marked as closed issues) \cite{sandquist}, expressed users’ curiosity about the template for implementing a similar approach for their own company, tools and infrastructure-related questions and transparency across platforms. The post announced that Microsoft has made all their documentation open-sourced. Users can now view and make changes to all the documentation source files written in the Markdown format on GitHub, the platform used by Microsoft to host their product documentation. Although viewing source files is open to the public, the editing feature is not as direct as one would expect. Along with being a collaboration platform, Github also acts as a version control tool for project management. Instead of making changes directly to the source files, GitHub provides the  Propose changes feature for editing content which allows users to create a pull request, essentially a copy of the project with the new changes maintaining the original version. Original creators or moderators of the content can then review those changes and make decisions about using it for the published version. Such a pull request, while enabling collaborative authoring, provides a space for collaborators to communicate about changes, express ideas, assign tasks, discuss details, and conduct reviews (see chapter \ref{chap-three} for more details about GitHub and other infrastructural functions). This idea of allowing collaborations from multiple stakeholders and especially users intrigued technical communicators engaged in more traditional practices of documenting product information, who then wanted to adopt the open authoring approach.

Before making major infrastructural changes to move to an open authoring approach it is important that technical communication teams understand the affordances of such a system, implications for the organization as a whole, social and technological challenges of accepting and managing user inputs, and their own role in the process of converting users' inputs to knowledge. These considerations raise several questions such as, what are the ways to collect inputs from users, how can we handle the inputs, who is responsible for doing that,  what are the other dependencies, and so on. This project attempts to address a few of these questions by acknowledging the contributions of previous audience analysis studies, identifying the limitations of past literature, and suggesting new ways to consider making changes to the technical communication processes. The contributions of this research will highlight the value of user contributions in documentation development practices by pointing to practical implementations of utilizing it, and learning about their implications on the technical communication field. 

Collaborating with stakeholders, especially users, is not a new phenomenon in the technical communication industry. At the SIGDOC 2001 conference, \textcite{berglund2001open} discussed the use of open source documentation as a solution to alleviate the pressure on writers who handle increasing amounts of content changes with fewer and fewer resources. They argued that successful open source documentation systems are highly dependent on the projects' abilities to attract and accumulate large numbers of users who are invested in its development. Limitations of these systems are that smaller projects may have difficulties producing enough user contributions and users may not be able to participate at all if they have questions but no answers on how to solve them. Technical communicators would merely act as gatekeepers and moderators for FAQs and formal documentation, and as literate expert users of the system they are documenting \cite{berglund2001open}. The Microsoft model removes the dependency on users and changes their role to secondary contributors. This model of partial user involvement in the documentation process is popularly known as the 'Open Authoring Approach'. Apart from Microsoft, many other companies have now started adopting this model including IBM, Citrix and so on. While this approach preserves the advantage of just-in-time improvements in user-driven content provided by fully open sourced documentation systems, it provides a platform to encourage user interaction for large and small scale projects alike.

Historically, users have primarily been content consumers. The field of technical communication developed during the world wars and has since then evolved to satisfy various audience needs \cite{swarts2018wicked}. Technical communicators are generally responsible for creating information products like instructions/manuals, web sites, and presentations, as well as develop definitions, social media content and grants/proposals \cite{blythe2014professional, kimball2015training, baehr2015complexities, dubinsky2015products}. These information products belong to different genres and produce distinct content types for a variety of audiences. \textcite{brumberger2015evolution} found that the most essential skills to produce them were technical communicators’ abilities to collaborate with subject-matter experts and co-workers, to write clearly for specific audiences and purposes. Scholars have also emphasized the abilities to focus on analyzing user needs, utilizing word-processing and document-design software, learning to assess and use new technology; and motivate, critique, and evaluate oneself constantly \cite{rainey2005curricula} while producing content. Over time, users and technologies together and separately have led to alterations in the ways in which technical communication is performed. These alterations help us understand the history of the field. Coincidentally, in the technical communication business, documentation histories are maintained by tracking alterations in content commonly referred to as ‘revisions’. Groups invested in information-making often negotiate numerous socio-technical and rhetorical barriers \cite{coppola2006guest, doheny1992rhetoric} to create knowledge despite alterations. 

\section{User needs}
Analyzing user needs is the ability to listen to users in a timely manner and facilitate the spread of knowledge that originates in the body and context of an individual content developer, so that others can use it \cite{johnson2013solving}. Most researchers and theorists have argued for technical communicators to be involved actively in all stages of the process with a primary role as a “user advocate” \cite{carroll1996ten, redish2010technical, spinuzzi2000investigating}. Yet, there is evidence that, even with decades of research to support this role, many companies do not fully integrate their technical communicators or permit them to exercise this role as user advocates by having contact with users \cite{virtaluoto2014death}. This work is carried out by other user-facing teams in the organization like business analysts. When users get involved with content creation, it gives writers an opportunity to learn about their users from the content being created. This phenomenon is fairly new. Technical communicators traditionally had other ways of understanding their audience needs.

One approach to understand specific audience needs is to fictionalize them. \textcite{ong1975writer} argued that the writer must “construct in his imagination, clearly or vaguely, an audience cast in some sort of role” and that “audience is a collective” – they share needs and preferences. However, documentation audiences are more subjective than that in terms of how they read and use documentation. Therefore, \textcite{ross2013deep} argues that the phenomenon of defining and analyzing audiences is increasingly complex in technical communication. Ross also provides a brief description on different audience analysis approaches. \textcite{ede1984audience} work relied on demographic inputs about audiences to understand them. \textcite{warren1993three} demands to expand the method to include organizational and psychological analyses along with demographics. Albers’ method of multidimensional audience analysis accounts for audiences’ needs and expectations in relation to levels of knowledge, detail, and cognitive abilities \cite{albers2004communication}. Persona driven approaches also account for demographic and cognitive abilities. \textcite{coney2000role} express the need to input rhetorical conceptions that include more details about communication situations in persona design. The approaches mentioned so far do not consider readers' feedback that can be used to understand audience needs and problems more precisely to update documentation. \textcite{schriver2010document} introduced the feedback-driven approach akin to participatory design and usability testing methods. Several studies have followed suit to not only acknowledge user participation, but also to study their impact on documentation practices \cite{johnson2013solving, swarts2018wicked}. The next chapter provides a detailed overview of audience analysis methods and the intersections with other disciplines pursuing the idea of uncomplicating the audience phenomenon. As we start looking at audiences as active participants and contributors of knowledge in open authoring models we can closely follow their role in product documentation processes in software companies. Thus it becomes critical that we learn not only about the information products but also about the collaborative content production processes.

\section{Collaborative content development}
While illustrating the complexity of knowledge development processes in an organization, \textcite{slattery2007undistributing} describes the distribution of organizational resources, multiple texts and technological products. Technical documentation is produced through the act of coordination of several texts including past versions of the documentation set, a series of drafts and revisions, inputs from other teams (especially product developers), emails, messages resulting from project management activities and several other sources. While consolidating multiple texts into one document, several rhetorical negotiations are made. These coordination activities resonate with Johnson-Eilola’s idea of symbolic-analytic work \cite{johnson1996relocating}. Symbolic analysts attempt to solve problems with information, texts, and images \cite{johnson1996relocating}. They find, arrange, synthesize, and transform existing texts to meet the needs of diverse users. The key to understanding the process of coordination thus is to pay attention to the stage of how raw content gets transformed into useful knowledge. It can be studied by observing how content moves from one system to another, from one user group to another, and even from one culture to another \cite{johnson2013solving}. Another important factor in coordination is the use of the same underlying technology used to produce and merge content. The ability to transfer content in one format to be captured and manipulated into another, lays the foundation of what some scholars refer to as ‘micro-content’ \cite{shank2008web, johnson1996relocating}, or the parts of content that collaborators (including writers) create that later fit into a finished information product. Anderson states that this content management process benefits from using content management systems (CMS) that automate and support the process of storing, managing, and publishing content objects \cite{andersen2011component}.  \textcite{jenkins2004cultural} and \textcite{hart2010content} argue that content management systems enable cross-department collaborations. \textcite{hackos2002content} and  \textcite{clark2007content} describe the role of CMS as a content organizer, separating, categorizing and delivering information to users in desired formats. Although these works discuss CMSs as process-oriented technologies, they do not acknowledge user participation in content development. While Hart-Davidson asserts that “the whole organization must write, and write well” (\cite{johnson2013solving}, p. 59), user contributions received through sources beyond the CMSs are ignored. How beneficial would it be to share CMS’s access with users to create open authoring platforms? And how does that change the role of a technical communicator?

\section{User participation}
User-generated content plays an important role in documentation cycles. Technical communicators are finding ways to gather user-generated data and using it to improvise content to resolve audience concerns \cite{dubinsky2015products, swarts2018wicked}. Users are becoming more involved in writing content for organizations than ever before. For example, ‘wiki-based documentation platforms’ for products such as \href{http://fit.c2.com/wiki.cgi/}{Fit} and \href{http://knoppix.net/wiki3/index.php?title=Main_Page/}{Knoppix} or ‘user forums’ such as those for \href{https://discussions.apple.com/}{Apple} and \href{https://access.redhat.com/discussions}{Red Hat} are great places to get insights about users’ queries and concerns. As most product documentation systems have become web-based, commenting features have become commonplace. Unlike traditional print or PDF documents, web access offers users an opportunity to engage with the documentation as well as with each other. It allows users to engage in reasoned opinion expression in an attempt to identify solutions to a common problem and/or to evaluate those solutions \cite{habermas1984habermas}. One method of enabling engagement as well as connecting with users is through the use of 'comments' \cite{Garg_2012}. In public sphere theory research, commentors is attributed to participatory methods as a means to provide input, to increase the throughput and by enabling decision making by creating consensus or dissent \cite{chung2008audience, springer2015user}. User knowledge about their specific use cases, needs or problems they experience, contributes towards making the content accurate. Users who do not contribute, also called lurkers may observe user-generated communications at all stages, from input to output \cite{larsson2011interactive}. Lurkers impact web-based communication positively \cite{springer2015user}. Actions that result from user comments if noticed, encourage contribution from lurkers as they become more aware of participation opportunities. Gallagher affirms the use of online comments as tools that help deepen our understanding of the way audience interaction processes emphasize production and distribution of content \cite{gallagher2020update}. This study is designed to look at other ways (apart from the ones mentioned here) to investigate users' interactions that help us understand audiences.

This leads us to an important question – how are users different from audiences? Researchers have frequently toyed with this question when studying interactive spaces. Webb describes users as a subset of audiences \cite{webb2013techniques}. He explains that users can be categorized in the following ways: low-level audiences such as implementors, medium level such as those who install and maintain the product and finally high-level users popularly known as end-users, those who use the product in its normal and intended manner \cite{webb2013techniques}. The last category of users can be categorized as stakeholders, customers or technical decision-makers who make the purchase decision but who may never use the product. \textcite{laurel2013computers} makes use of metaphors to compare software audiences to theatre audiences. Laurel compares interface design to a theatre stage where actors perform, delivering content to their audiences in the form of a play. Audiences are not aware of the technical aspects responsible for content production and presentation. If we introduce the idea of interaction into the space, where audiences are merely engaged in passive content reception, \textcite{laurel2013computers} argues, that we will need to reconsider aspects of audience (human) agency. She defines "users" as the human actors who, by participating and interacting with the system, in this case, the performance happening on the stage, "are like audience members who are able to have the greatest influence on the unfolding action" (p. 26) than simply absorbing the content being shared with them. These users are set apart from the audience due to their own peculiar ways of connecting, interacting, communicating or participating in the act of content production. Just like any interface, the backend – technical aspects responsible for content production and presentation – remains foreign to these users, they stand out in the content ecology. Going back to Laurel's analogy of a theatre, these new participants would not know the script and their clothes and skin would not match the other actors' on stage. To get the unprecedented situation in control, the actors would "attempt to improvise action that could incorporate the interlopers and still yield something that had any dramatic integrity". That is, the core content production team would need to make improvisations to incorporate the new content produced as a result of participant(s) interactions. This is where open authoring moves away from open sourced documentation. Instead of being participants, users become improvisers of content, but they do so by contributing.  

\section{Exigency for research}
In collaborative technical communication spaces, where collaborators interact using any means of participation like forum posts, feedback comments or edits to wiki-based documentation systems, the value of technical communicators work remains of the utmost importance when functioning as an intermediary between the content experts and those users. By more clearly adopting the roles of director and editor they become user advocates in the field \cite{redish2010technical}. While citing Weiss’ work, \textcite{albers2004communication} explains that with most of the challenges of usability and communication already solved (or handled by other teams), technical communicators’ roles need to evolve. A possible direction for evolution is to become problem solvers and designers who along with creating content also handle user requests by architecting content management systems and documentation databases \cite{albers2004communication}. The backend of product documentation which involves the tools and technologies make it harder for audiences to participate in content production processes. \textcite{swarts2018wicked} argues that such design issues complicate social adaptation and need to be replaced by Mirel’s ‘constructivist’ documentation approach in order to include the social, cultural, and technological dynamics of users’ work. Technical communicators' role as information architects must be to become mediators between technologies and users. To gauge user problems, their contributions need to be closely monitored. Sharing the genre understanding, context and technology will motivate users to participate in organizational processes enabling technical communicators to interact with them more directly.

Understanding the significance of technical communicators' changing role is more important now, than ever before. We know that users' participation, collaborative partnership with technical communicators and content generative actions help us understand them better. But user analysis is only one of the reasons. The other reason is that we need to predict the changes in technical communicators' roles to be prepared for the rapidly changing information economy. In 1996, Johnson-Eilola argued that we live and work in a post-industrial age, where information is fast becoming the more valuable product. Although products are still manufactured and purchased, their primary value lies in information \cite{johnson1996relocating}. Due to this, the task of information management was often entrusted upon employees (especially technical and professional communicators) to safeguard and carry out flawlessly. But soon markets realized that the real value of information can be derived through circulation and association. Circulation refers to information being made easily accessible so that users can share it among their networks which increases its value. Further, the networks revealed that there were still gaps in information owing to socio-political differences. An association space helps both – information developers and users – think of information in a more social, intertextual, dialogic,  socially responsible and active way \cite{johnson1996relocating}. The World Wide Web makes associations possible providing networked users a space to help fill those gaps \cite{johnson1996relocating}. With the expansion of WWW, we have witnessed the rise of decentralized web (information) technologies like wikis, social media platforms, user forums, etc. The technical communication field has been directly impacted by some (if not all) of these technologies.

Crowd-sourced documentation systems like wikis are on a rise since 2006. In his Ph.D. dissertation, Thominet argues that the crowdsourced form of documentation using wikis is valuable for two reasons: first, it helps resolve systemic destabilization in documentation systems and second, it offers technical communicators a means to build a relationship with their user community \cite{thominet2016emerging}. Destabilizations occur as a result of contradictions in sociocultural activity. In other words, since each user can have a unique way of using a product, documentation produced by experts who have domain knowledge (in technical communication and/or system expertise) can fail to meet the needs of the community. Gentle explains a similar concern, that is, the limits of any single person’s knowledge and the need to interact with customers, for explaining the move towards wiki-based systems for documentation. However, wiki technology complicates notions of usable design as the information architecture of a wiki site may be created on the fly by all participants rather than by a dedicated technical communicator. Johnson explains other drawbacks of wiki-based systems which include a constant need for moderation, complex infrastructure limiting the editing and publishing processes and unstyled content \cite{johnson1996relocating}. Similarly, while user forums enable user participation globally thus enhancing group cultural and social perspectives, forums often produce a large volume of posts. They also need constant moderation and additionally also lack contextual cues \cite{white2001receiving, o2009structured} present in wikis. Crowd-based systems thus require technical communicators' intervention "to shape, stylize, make consistent, and organize the content to make it usable" \cite{johnson_2007}. In the same article Johnson draws attention to the fact that although technical communicators "would write 75\% of the content anyway, it will be more informed and accurate" due to user participation. An important point to note from Johnson's argument is the amount of content contributed by users.

Users add value to documentation not just by increasing the quality through associations, but also by writing considerable portions of the required content. The amount of content being written has grown tremendously over the last decade. In his presentation at the STC Silicon Valley chapter meeting (on November 14, 2016), Ralph Squillace stated that Microsoft’s product documentation has grown exponentially and now consists of more than 45 million topics. The topic-based authoring approach is responsible for generating an equal number of independent web pages to publish those topics. The problem of information overload has become ubiquitous and is not new. In fact, information overload was experienced long before the appearance of the Internet. Philosophers like Socrates believed that the problem began when humans learnt to write. Human history is a long process of accumulating information, especially once writing made it possible to record texts and preserve them beyond the capacity of our memories \cite{blair2010too}. And if we look closely, we can find a striking parallel to the history of technical documentation. The invention of printing in the 15th century led to a flood of books in the market. As audiences became more diverse, the need for documentation became a standard practice resulting in loads of content. Just like Word processing software replaced slips of paper used for cutting and pasting information from manuscripts and printed matter, single-sourcing and topic-based authoring allowed breaking up of content into topics so that they could be reused. The tables of contents and alphabetical indexes developed to provide guidance for larger books resemble the navigation of other information access tools that are provided to documentation users. Some of the methods like internal and external search are exactly similar. Algorithms and data structures made it possible to respond to users' search queries within seconds. Electronic media revolutions led to the spread of information far and wide. The most significant media revolution was the Internet which made overload spread beyond scholarly fields into users' day-to-day activities like shopping and entertainment, and visible to anyone doing a basic Internet search. Another substantial change brought about by the Internet was less expensive publishing \cite{blair2010too}. Before the rise of the Internet, media used for publishing was expensive. The process of filtering made sure that only the most valuable content was published. This changed and the amount of content being published grew and the amount of filtered content reduced. While printed material requires longer to be produced and propagated, Internet content moves quickly, making it possible to release products and accompanying documentation every year or even every week (as seen in recent software products). It is not uncommon for software companies to have one-week release cycles (see Release cycle by Smartsheet) where product updates, also known as patches, and related documentation are pushed to the users constantly. The other aspect of information overload is the need to share and contribute to information. Constant updates have fueled users' enthusiasm for experimenting with the new forms of products, accumulating corresponding information and sharing the knowledge with others who could benefit from it. Contributors are driven by this enthusiasm, even beyond their hopes for acquiring reputation or financial gain. In democratizing the ability to contribute to each and every shared experience, we have opened doors for information increase without figuring out the best way to deal with the content \cite{coleman2008hacker, blair2010too}. Clay \textcite{shirky2008here} calls this phenomenon a "filter failure" - our systems for managing information abundance are swamped by the growth of information (at the Web 2.0 Expo). This problem has had and will impact the field of software documentation. This case may be unique for the genre of technical communication because users have historically relied on published content on product documentation websites. The development of user generated content may be an interesting genre situation, but from the perspective of technical communicators, this orientation of publishing content before filtering content is socially responsible, reduces content quality and impacts the representation of the organization that they are part of. This puts an added level of organizational process requirement, in other words, a filter, to wrestle with the new idea of democratized power distribution around information circulation and access.

Due to the emphasis on horizontal communication, coworking and ubiquitous access to social software, organizational boundaries are blurring leading to the opening of black boxed organizational processes to accommodate potential collaborators’ activities \cite{spinuzzi2009starter}. Technical communication research has adapted to managing and designing content architecture to control ways in which it is published to gain trust from users. However, so far, most of the research manages to explore avenues of social software platforms like social media \cite{spinuzzi2009starter}, user forums \cite{spinuzzi2000investigating, paretti2007teaching, slattery2007undistributing, swarts2007mobility}, wikis \cite{jones2008patterns, swarts2007mobility, slattery2009edit}, which are inherently designed to display users' contributions as disconnected from the organizational processes \cite{grabill2003divides, harrison2003methodological, spinuzzi2003open, zappen2006developing, swarts2007mobility, andersen2011component, potts2019boycotting}. These works have helped us look at social structures and technical infrastructures and in some cases content management systems. Technical communicators view textual production as a dynamic and iterative process through which meaning is contingent on culturally situated experiences. Some works have discussed the role of user centred design as a precursor to the shift of organizations' process improvement activities that have helped in the inclusion of project management in TPC curriculum \cite{hart2007coming, dicks2000paradox, lauren2018communicating}. However, TPC scholars haven't yet dived deeper into looking at formalized genres of publication, especially avenues like product documentation websites with respect to user correspondence. Such formal genres compile the many unofficial voices, black-box them \cite{latour1987science} into a single official, authoritative voice before being released \cite{spinuzzi2009starter}. The genre develops by incorporating more regulated moves that instantiate the assumptions of the activity. By opening those black boxed processes we'll learn more about how user voice is transformed into the organizations standard knowledge form. Following the assumptions drawn from relevant current works, this study aims at studying intersections between the market, organizational practices, rhetorical vectors and technologies and ways in which they impact the role of a technical communicator in organizations. The study was set up to answer the following research questions:

\begin{enumerate}
  \item How does user contribution to knowledge production reshape our understanding of the audiences? What can we do to learn more about audiences through the content they create? 
    \item How does user contribution to knowledge production change the role of technical communicators?
\end{enumerate}

Examining constructs relating to these questions could help organizational leaders address issues with user participation, knowledge creation and knowledge sharing in technical communication spaces. Knowledge constructed through collaboration in these spaces could contribute to enhanced productivity and work quality, and signal competence to external stakeholders \cite{haas2007different}. Results from this study could help organizations understand the impact of user perceptions on the acceptance of technologies used for increasing knowledge sharing in virtual environments and to prevent losses on technology investments. The next section is a summary of chapters in this book that provide more detailed theoretical and methodological frameworks used to conduct this study, findings, recommendations and implications to the field of technical communication.

\section{Summary of research}
Chapter one discussed the background of the study and stated two primary research questions used to investigate the current technical communication spaces. It was used to enhance our understanding of the factors that help in shaping online product documentation, users' involvement in the documentation spaces, and technical communicators' contributions. The chapter discussed how open authoring, as a way to encourage users' involvement, with documentation content is increasing everyday. Such collaborations are leading to a large increase in online communities that has extended to corporate environments. Audience analysis methods discussed in the past scholarship falls short in understanding such audience phenomena. Therefore, we need new methods to record new data and contextualize audiences. 

Chapter two reviewed previous studies on audience analysis, acknowledged the value of this body of research, and identified some limitations. The previous theoretical frameworks were classified into into dichotomies in each of the fields: technical communication, composition, and rhetoric. It sets up a platform to discuss the complex nature of audience interactions to understand why audiences' involvement with content lies on a spectrum and cannot rest on these dichotomies. The limitations of current literature not confirms the exigence, but also helps in choosing methodologies that go beyond what are currently available. 

Chapter three sets out to describe the methods used for this study. The research uses a two-step framework: first is a qualitative analysis of interviews with practitioner to choose case studies from technical documentation spaces in software companies; second, case study analysis using Actor Network Theory (ANT). The background of ANT (theoretical framework for this study) is described to introduce the notions of control and translation, and the principles of generalised symmetry, agnosticism, and free association through which user interactions entailing the use of a collaborative technology can be studied. This chapter was used to propose guidelines to be used as to inform the analysis of Chapter four, in which case studies were explored closely in the light of ANT. The chapter concluded by discussing previous controversies and potential limitations of ANT.

Chapter four describes the findings gathered from analyzing case studies. The analysis was informed by the sociology of translation and its related concepts as discussed in Chapter 3. Prior to tracing the main findings, each case study was described as being composed of different actor-networks. Further, a chronological narrative of how actor-networks get formed, how relationships between actors are established, and what roles do audiences and technical communicators play in those networks, were described in which primary attention is given to how the focal actors attempt to enrol audience actors (roles) to support their participation in knowledge development. This chapter answers the first research question by carefully tracing how interactions lead to content production. 

Chapter five helps in answering the second research question by highlighting technical communicators' roles in open authored documentation systems. Key findings of the research were mapped to the current understanding of audiences, to point out what is missing in those conceptualizations, and make recommendations on how to track the evolving nature of audiences and their participation in knowledge networks. A methodological process consisting of a three-step framework (planning-implementation-testing) is proposed that can enable technical communicators to use their existing humanities knowledge and computational skills to conduct detailed audience studies by finding ways to collect audience data by recording audience interactions, and making useful collaborations to find meaning from that data.

Chapter six encapsulated the key content of previous chapters and provides details about how the aims of the study were met, how the research questions were answered, and how the findings can be applied to the study and practice of technical communication. It lists out the pedagogical implications of the study and proposes two methods of bringing audience analyses discussions in classrooms. The chapter also suggests the implications of this research and contributions it can make to the practice of technical communication. The chapter concludes by listing the gaps and limitations of this research that will be addressed through future work. 
